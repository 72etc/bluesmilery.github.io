<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Reinforcement learning part 1 - Introduction | Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="本文是在学习David Silver的Reinforcement learning课程过程中所记录的笔记。因为个人知识的不足以及全程啃生肉，难免会有理解偏差的地方，欢迎一起交流。
课程资料：http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html
关于 Reinforcement learning的两本参考：An Introduction">
<meta property="og:type" content="article">
<meta property="og:title" content="Reinforcement learning part 1 - Introduction">
<meta property="og:url" content="https://bluesmilery.github.io/blogs/481fe3af/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="本文是在学习David Silver的Reinforcement learning课程过程中所记录的笔记。因为个人知识的不足以及全程啃生肉，难免会有理解偏差的地方，欢迎一起交流。
课程资料：http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html
关于 Reinforcement learning的两本参考：An Introduction">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899734922849.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899734922849.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738577258.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738681541.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738907877.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899739116563.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899739230370.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740173215.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740482901.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740959159.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741166405.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741288849.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741764026.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741876773.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741929501.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899742097642.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899743659769.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899744403314.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899744486361.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899747156548.png">
<meta property="og:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899747263385.png">
<meta property="og:updated_time" content="2017-03-20T03:01:12.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Reinforcement learning part 1 - Introduction">
<meta name="twitter:description" content="本文是在学习David Silver的Reinforcement learning课程过程中所记录的笔记。因为个人知识的不足以及全程啃生肉，难免会有理解偏差的地方，欢迎一起交流。
课程资料：http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html
关于 Reinforcement learning的两本参考：An Introduction">
<meta name="twitter:image" content="https://bluesmilery.github.io/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899734922849.png">
  
    <link rel="alternate" href="/atom.xml" title="Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">A Zone for Knowledge</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://bluesmilery.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Reinforcement learning part 1 - Introduction" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blogs/481fe3af/" class="article-date">
  <time datetime="2017-03-20T01:24:02.000Z" itemprop="datePublished">2017-03-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Reinforcement learning part 1 - Introduction
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文是在学习David Silver的Reinforcement learning课程过程中所记录的笔记。因为个人知识的不足以及全程啃生肉，难免会有理解偏差的地方，欢迎一起交流。</p>
<p>课程资料：<a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" target="_blank" rel="external">http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html</a></p>
<p>关于 Reinforcement learning的两本参考：<br>An Introduction to Reinforcement Learning<br><a href="https://webdocs.cs.ualberta.ca/~sutton/book/the-book-1st.html" target="_blank" rel="external">https://webdocs.cs.ualberta.ca/~sutton/book/the-book-1st.html</a><br>Algorithms for Reinforcement Learning<br><a href="https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf" target="_blank" rel="external">https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf</a></p>
<a id="more"></a>
<h2 id="1、About-Reinforcement-Learning"><a href="#1、About-Reinforcement-Learning" class="headerlink" title="1、About Reinforcement Learning"></a>1、About Reinforcement Learning</h2><p>Many Faces of Reinforcement Learning<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899734922849.png" alt=""><br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899734922849.png" width="50%" height="50%"><br>Machine Learningd的三个分支：Supervised Learning、Unsupervised Learning、Reinforcement Learning<br>RL与其他两种的区别：</p>
<ul>
<li>There is no supervisor, only <strong>a reward signal</strong></li>
<li><strong>Feedback is delayed</strong>, not instantaneous</li>
<li><strong>Time</strong> really matters (sequential, non i.i.d data)</li>
<li>Agent’s <strong>actions affect the subsequent data</strong> it receives</li>
</ul>
<h2 id="2、The-Reinforcement-Learning-Problem"><a href="#2、The-Reinforcement-Learning-Problem" class="headerlink" title="2、The Reinforcement Learning Problem"></a>2、The Reinforcement Learning Problem</h2><p>介绍三个概念：reward、environment、state<br>==<em>reward==<br>用Rt来表示reward（标量，就是个’数’），衡量在第t步agent表现的好坏（收益），agent的目标就是最大化累计reward<br>Reinforcement learning is based on the <em>*reward hypothesis</em></em>（All goals can be described by the maximisation of expected cumulative reward）<br>简而言之就是假设所有的目标都可以用最大化累计收益来表示<br>example：<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738577258.png" alt=""></p>
<p>Sequential Decision Making<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738681541.png" alt=""></p>
<p>==environment==<br>agent与environment的关系，agent执行action影响environment，environment给agent关于observation和reward的反馈<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738907877.png" alt=""></p>
<p>==state==<br><em>history</em>：在第t步之前的observation、reward、action。注意没有At，因为agent是基于observation和reward来选择action，在选择action之前的这个时间点，在此之前的都算是过去<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899739116563.png" alt=""></p>
<p><em>state</em>：is the information used to determine what happens next。就是说我利用了history中某些信息来判断接下来会发生什么，所利用的这些信息就被称为state<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899739230370.png" alt=""></p>
<p>这里what happens next分为两部分</p>
<ul>
<li>The agent selects actions。agent会选择什么action</li>
<li>The environment selects observations/rewards。environment会给出什么observation/reward</li>
</ul>
<p>state又分为environment state、agent state、information state<br><em>environment state</em>：Ste is the environment’s private representation。对于agent而言一般是invisible的，就算是visible，那也包含不相关的信息<br><em>agent state</em>：Sta is the agent’s internal representation。It can be any function of history<br><em>information state</em>：又被称为markov state。所以具有’The future is independent of the past given the present’<br>The environment state and the history are Markov</p>
<p>例子：每一行为一次过程，第一次灯亮灯亮，老鼠按下开关，然后铃响，结果老鼠遭到电击。第二次先铃响灯亮，然后老鼠两次按下开关，结果老鼠得到奶酪。第三次老鼠先按下开关，然后灯亮，然后老鼠又按下开关，然后铃响，猜测老鼠会得到什么？<br>分析：如果agent state是利用最后三个动作的顺序，那么老鼠会遭到电击。如果agent state是利用灯亮铃响按下开关的次数，那么老鼠会得到奶酪。如果agent state是利用整个序列，那我们也不知道会发生什么<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740173215.png" alt=""></p>
<p><em>Fully Observable Environments</em>：agent <strong>directly</strong> observes environment state。这种被称为<strong>Markov decision process</strong> (MDP)<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740482901.png" alt=""></p>
<p>agent state = environment state = information state</p>
<p><em>Partially Observable Environments</em>：agent <strong>indirectly</strong> observes environment。这种被称为<strong>partially observable Markov decision process</strong>（POMDP）</p>
<ul>
<li>A robot with camera vision isn’t told its absolute location</li>
<li>A trading agent only observes current prices</li>
<li>A poker playing agent only observes public cards<br>agent state 不等于 environment state<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740959159.png" alt=""></li>
</ul>
<h2 id="3、Inside-An-Reinforcement-Learning-Agent"><a href="#3、Inside-An-Reinforcement-Learning-Agent" class="headerlink" title="3、Inside An Reinforcement Learning Agent"></a>3、Inside An Reinforcement Learning Agent</h2><p>agent的三要素</p>
<ul>
<li>Policy：agent采取的行为策略（behaviour function）</li>
<li>Value Function：评估state/action的好坏</li>
<li>Model：agent对environment所构建的模型（在agent眼中environment的样子）</li>
</ul>
<p>==Policy==：agent的策略，也就是agent在某个状态会采取什么样的行动，所以policy is a map from state to action<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741166405.png" alt=""></p>
<p>==Value Function==：是对未来收益的一个预测，用来评估状态的好坏程度<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741288849.png" alt=""></p>
<p>其中gamma是discounted系数，表示了未来的收益对现在的影响，越远的影响越小。比如gamma是0.9，那么这个预测的时间跨度大约是未来三四十步</p>
<p>example：左上角那个是state value function，游戏画面上有一个紫色的，那个是mothership，击落的分数奖励更高，所以当mothership从右边出现后，对未来收益的预测增加，从而value function的值开始上升。当mothership从眼前过去后，不管打没打中，value function都会陡然下降，因为后面都是小兵，所以对未来收益的预期也就回到了一般水平。<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741764026.png" alt=""></p>
<p>还有个打砖块的例子，越靠上面的砖块分数越高，所以在游戏刚开始的时候value function比较平滑，当下面的打了好多以后，打到更深的砖块的概率上升，所以value function的波动增加了。<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741876773.png" alt=""><br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741929501.png" alt=""></p>
<p>==Model==：agent对environment构建的模型，用来预测environment下一步会干什么（会跳转到哪个state，会给出什么reward）<br>P predicts the next state<br>R predicts the next (immediate) reward<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899742097642.png" alt=""></p>
<p>基于上面三要素，RL agent有以下几种分类<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899743659769.png" alt=""></p>
<h2 id="4、Problems-within-Reinforcement-Learning"><a href="#4、Problems-within-Reinforcement-Learning" class="headerlink" title="4、Problems within Reinforcement Learning"></a>4、Problems within Reinforcement Learning</h2><p>==Learning and Planning==<br>Two fundamental problems in sequential decision making</p>
<ul>
<li>Reinforcement Learning:<ul>
<li><strong>The environment is initially unknown</strong></li>
<li>The agent interacts with the environment</li>
<li>The agent improves its policy</li>
</ul>
</li>
<li>Planning:<ul>
<li><strong>A model of the environment is known</strong></li>
<li>The agent performs computations with its model (without any external interaction)</li>
<li>The agent improves its policy</li>
<li>a.k.a. deliberation, reasoning, introspection, pondering, thought, search<br>Reinforcement Learning的例子：游戏的机制不清楚，只能通过玩来学习，通过观察得分与游戏画面来选择下一步行动<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899744403314.png" alt=""></li>
</ul>
</li>
</ul>
<p>Planning的例子：游戏机制很清楚，下一步是什么样子的都知道，有完整的策略（就像是玩游戏有攻略一样）<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899744486361.png" alt=""></p>
<p>==Exploration and Exploitation==<br>Reinforcement learning is like trial-and-error learning</p>
<ul>
<li>Exploration：探索，更多的去探索environment的信息</li>
<li>Exploitation：利用，更多的利用已知的environment信息来最大化reward<br>举个例子，吃饭选择餐厅，exploration是选择一个新餐厅，exploitation是选择自己平时最喜欢吃的餐厅</li>
</ul>
<p>==Prediction and Control==<br>Prediction：估计未来的收益，given a policy<br>Control：最优化未来的收益，find the best policy</p>
<p>Gridworld Example，没看懂<br>后记：有了一些理解，如果移动到A的话那么就会跳转到A’，并且reward +10，如果移动到B的话那么就会跳转到B’，并且reward + 5<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899747156548.png" alt=""><br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899747263385.png" alt=""></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://bluesmilery.github.io/blogs/481fe3af/" data-id="cj0hgymva00036jmvq70d7gx8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/增强学习RL/">增强学习RL</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/blogs/9a018dfc/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习系统环境配置指南 —— GTX 1080 + Ubuntu16.04 + CUDA8 + cuDNN5.1 + TensorFlow</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/增强学习RL/">增强学习RL</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/增强学习RL/" style="font-size: 10px;">增强学习RL</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blogs/481fe3af/">Reinforcement learning part 1 - Introduction</a>
          </li>
        
          <li>
            <a href="/blogs/9a018dfc/">机器学习系统环境配置指南 —— GTX 1080 + Ubuntu16.04 + CUDA8 + cuDNN5.1 + TensorFlow</a>
          </li>
        
          <li>
            <a href="/blogs/1509af3a/">Linux系统安装——Ubuntu16.04+Windows7双系统</a>
          </li>
        
          <li>
            <a href="/blogs/4a17b156/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Gai<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>