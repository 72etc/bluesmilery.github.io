<!DOCTYPE html>
<html lang="">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="增强学习 Reinforcement learning part 1 - Introduction"/>




  <meta name="keywords" content="增强学习RL, Blog" />










  <link rel="alternate" href="/default" title="Blog">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.6.0" />



<link rel="canonical" href="https://bluesmilery.github.io/blogs/481fe3af/"/>


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.6.0" />






  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "BmUgD1geFKBFQpURVdGNzgl1-gzGzoHsz",
      appKey: "mOzxpdEEenjouuAKMFPazvnd"
    });
  </script>





    <title> 增强学习 Reinforcement learning part 1 - Introduction - Blog </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Blog</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          增强学习 Reinforcement learning part 1 - Introduction
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017-03-20
        </span>
        
        
        <div class="post-visits"
             data-url="/blogs/481fe3af/"
             data-title="增强学习 Reinforcement learning part 1 - Introduction">
            阅读次数
          </div>
        
        
        
        
          <span class="post-count">本文共1,452字</span>
          <span class="post-count">阅读约6分钟</span>
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、About-Reinforcement-Learning"><span class="toc-text">1、About Reinforcement Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、The-Reinforcement-Learning-Problem"><span class="toc-text">2、The Reinforcement Learning Problem</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、Inside-An-Reinforcement-Learning-Agent"><span class="toc-text">3、Inside An Reinforcement Learning Agent</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、Problems-within-Reinforcement-Learning"><span class="toc-text">4、Problems within Reinforcement Learning</span></a></li></ol>
    </div>
  </div>


    <div class="post-content">
      
        <p>本文是在学习David Silver所教授的Reinforcement learning课程过程中所记录的笔记。因为个人知识的不足以及全程啃生肉，难免会有理解偏差的地方，欢迎一起交流。</p>
<p>课程资料：<a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" target="_blank" rel="external">http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html</a></p>
<p>关于 Reinforcement learning的两本参考：<br>An Introduction to Reinforcement Learning<br><a href="https://webdocs.cs.ualberta.ca/~sutton/book/the-book-1st.html" target="_blank" rel="external">https://webdocs.cs.ualberta.ca/~sutton/book/the-book-1st.html</a><br>Algorithms for Reinforcement Learning<br><a href="https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf" target="_blank" rel="external">https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf</a></p>
<a id="more"></a>
<h2 id="1、About-Reinforcement-Learning"><a href="#1、About-Reinforcement-Learning" class="headerlink" title="1、About Reinforcement Learning"></a>1、About Reinforcement Learning</h2><p>Many Faces of Reinforcement Learning<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899734922849.jpg" width="40%" height="40%"><br>Machine Learningd的三个分支：Supervised Learning、Unsupervised Learning、Reinforcement Learning<br>RL与其他两种的区别：</p>
<ul>
<li>There is no supervisor, only <strong>a reward signal</strong></li>
<li><strong>Feedback is delayed</strong>, not instantaneous</li>
<li><strong>Time</strong> really matters (sequential, non i.i.d data)</li>
<li>Agent’s <strong>actions affect the subsequent data</strong> it receives</li>
</ul>
<h2 id="2、The-Reinforcement-Learning-Problem"><a href="#2、The-Reinforcement-Learning-Problem" class="headerlink" title="2、The Reinforcement Learning Problem"></a>2、The Reinforcement Learning Problem</h2><p>介绍三个概念：reward、environment、state<br>==<em>reward==<br>用Rt来表示reward（标量，就是个’数’），衡量在第t步agent表现的好坏（收益），agent的目标就是最大化累计reward<br>Reinforcement learning is based on the <em>*reward hypothesis</em></em>（All goals can be described by the maximisation of expected cumulative reward）<br>简而言之就是假设所有的目标都可以用最大化累计收益来表示<br>example：<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738577258.png" width="50%" height="50%"><br>Sequential Decision Making<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738681541.png" width="50%" height="50%"></p>
<p>==environment==<br>agent与environment的关系，agent执行action影响environment，environment给agent关于observation和reward的反馈<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899738907877.jpg" width="80%" height="80%"></p>
<p>==state==<br><em>history</em>：在第t步之前的observation、reward、action。注意没有At，因为agent是基于observation和reward来选择action，在选择action之前的这个时间点，在此之前的都算是过去<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899739116563.png" width="50%" height="50%"><br><em>state</em>：is the information used to determine what happens next。就是说我利用了history中某些信息来判断接下来会发生什么，所利用的这些信息就被称为state<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899739230370.png" width="50%" height="50%"><br>这里what happens next分为两部分</p>
<ul>
<li>The agent selects actions。agent会选择什么action</li>
<li>The environment selects observations/rewards。environment会给出什么observation/reward</li>
</ul>
<p>state又分为environment state、agent state、information state<br><em>environment state</em>：Ste is the environment’s private representation。对于agent而言一般是invisible的，就算是visible，那也包含不相关的信息<br><em>agent state</em>：Sta is the agent’s internal representation。It can be any function of history<br><em>information state</em>：又被称为markov state。所以具有’The future is independent of the past given the present’<br>The environment state and the history are Markov</p>
<p>例子：每一行为一次过程，第一次灯亮灯亮，老鼠按下开关，然后铃响，结果老鼠遭到电击。第二次先铃响灯亮，然后老鼠两次按下开关，结果老鼠得到奶酪。第三次老鼠先按下开关，然后灯亮，然后老鼠又按下开关，然后铃响，猜测老鼠会得到什么？<br>分析：如果agent state是利用最后三个动作的顺序，那么老鼠会遭到电击。如果agent state是利用灯亮铃响按下开关的次数，那么老鼠会得到奶酪。如果agent state是利用整个序列，那我们也不知道会发生什么<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740173215.jpg" width="50%" height="50%"></p>
<p><em>Fully Observable Environments</em>：agent <strong>directly</strong> observes environment state。这种被称为<strong>Markov decision process</strong> (MDP)<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740482901.png" width="50%" height="50%"><br>agent state = environment state = information state</p>
<p><em>Partially Observable Environments</em>：agent <strong>indirectly</strong> observes environment。这种被称为<strong>partially observable Markov decision process</strong>（POMDP）</p>
<ul>
<li>A robot with camera vision isn’t told its absolute location</li>
<li>A trading agent only observes current prices</li>
<li>A poker playing agent only observes public cards<br>agent state 不等于 environment state<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899740959159.png" alt=""></li>
</ul>
<h2 id="3、Inside-An-Reinforcement-Learning-Agent"><a href="#3、Inside-An-Reinforcement-Learning-Agent" class="headerlink" title="3、Inside An Reinforcement Learning Agent"></a>3、Inside An Reinforcement Learning Agent</h2><p>agent的三要素</p>
<ul>
<li>Policy：agent采取的行为策略（behaviour function）</li>
<li>Value Function：评估state/action的好坏</li>
<li>Model：agent对environment所构建的模型（在agent眼中environment的样子）</li>
</ul>
<p>==Policy==：agent的策略，也就是agent在某个状态会采取什么样的行动，所以policy is a map from state to action<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741166405.png" width="50%" height="50%"></p>
<p>==Value Function==：是对未来收益的一个预测，用来评估状态的好坏程度<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741288849.png" width="50%" height="50%"><br>其中gamma是discounted系数，表示了未来的收益对现在的影响，越远的影响越小。比如gamma是0.9，那么这个预测的时间跨度大约是未来三四十步</p>
<p>example：左上角那个是state value function，游戏画面上有一个紫色的，那个是mothership，击落的分数奖励更高，所以当mothership从右边出现后，对未来收益的预测增加，从而value function的值开始上升。当mothership从眼前过去后，不管打没打中，value function都会陡然下降，因为后面都是小兵，所以对未来收益的预期也就回到了一般水平。<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741764026.jpg" width="50%" height="50%"><br>还有个打砖块的例子，越靠上面的砖块分数越高，所以在游戏刚开始的时候value function比较平滑，当下面的打了好多以后，打到更深的砖块的概率上升，所以value function的波动增加了。<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741876773.jpg" width="80%" height="80%"><br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899741929501.jpg" width="80%" height="80%"></p>
<p>==Model==：agent对environment构建的模型，用来预测environment下一步会干什么（会跳转到哪个state，会给出什么reward）<br>P predicts the next state<br>R predicts the next (immediate) reward<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899742097642.png" width="50%" height="50%"></p>
<p>基于上面三要素，RL agent有以下几种分类<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899743659769.jpg" width="50%" height="50%"></p>
<h2 id="4、Problems-within-Reinforcement-Learning"><a href="#4、Problems-within-Reinforcement-Learning" class="headerlink" title="4、Problems within Reinforcement Learning"></a>4、Problems within Reinforcement Learning</h2><p>==Learning and Planning==<br>Two fundamental problems in sequential decision making</p>
<ul>
<li>Reinforcement Learning:<ul>
<li><strong>The environment is initially unknown</strong></li>
<li>The agent interacts with the environment</li>
<li>The agent improves its policy</li>
</ul>
</li>
<li>Planning:<ul>
<li><strong>A model of the environment is known</strong></li>
<li>The agent performs computations with its model (without any external interaction)</li>
<li>The agent improves its policy</li>
<li>a.k.a. deliberation, reasoning, introspection, pondering, thought, search</li>
</ul>
</li>
</ul>
<p>Reinforcement Learning的例子：游戏的机制不清楚，只能通过玩来学习，通过观察得分与游戏画面来选择下一步行动<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899744403314.jpg" width="80%" height="80%"><br>Planning的例子：游戏机制很清楚，下一步是什么样子的都知道，有完整的策略（就像是玩游戏有攻略一样）<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899744486361.png" width="80%" height="80%"></p>
<p>==Exploration and Exploitation==<br>Reinforcement learning is like trial-and-error learning</p>
<ul>
<li>Exploration：探索，更多的去探索environment的信息</li>
<li>Exploitation：利用，更多的利用已知的environment信息来最大化reward<br>举个例子，吃饭选择餐厅，exploration是选择一个新餐厅，exploitation是选择自己平时最喜欢吃的餐厅</li>
</ul>
<p>==Prediction and Control==<br>Prediction：估计未来的收益，given a policy<br>Control：最优化未来的收益，find the best policy</p>
<p>Gridworld Example，没看懂<br>后记：有了一些理解，如果移动到A的话那么就会跳转到A’，并且reward +10，如果移动到B的话那么就会跳转到B’，并且reward + 5<br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899747156548.png" width="50%" height="50%"><br><img src="/images/2017-03-20-Reinforcement learning part 1 - Introduction/14899747263385.png" width="50%" height="50%"></p>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="https://bluesmilery.github.io">Gai</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="https://bluesmilery.github.io/blogs/481fe3af/">https://bluesmilery.github.io/blogs/481fe3af/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/增强学习RL/">增强学习RL</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/blogs/18a3f212/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">机器学习 Machine learning part 1 - Linear Regression</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/blogs/9a018dfc/">
        <span class="next-text nav-default">机器学习系统环境配置指南 —— GTX 1080 + Ubuntu16.04 + CUDA8 + cuDNN5.1 + TensorFlow</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMzY4MC8xMDIzNQ">
        <noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
      </div>  
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



  <div class="social-links">
    
      
        
          <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
    
    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  
  <br>
  <span id="busuanzi_container_site_uv">
    被<span id="busuanzi_value_site_uv"></span>个小伙伴
  </span>
  <span id="busuanzi_container_site_pv">
    查看了<span id="busuanzi_value_site_pv"></span>次~
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2017 - 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Gai</span>
  </span>
</div>


      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  
   <script type="text/javascript">
	(function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
  </script>




    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  


    <script type="text/javascript" src="/js/src/even.js?v=2.6.0"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.6.0"></script>

  </body>
</html>
