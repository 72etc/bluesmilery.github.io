<!DOCTYPE html>
<html lang="">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="基于Docker的Kubernetes-1.12集群搭建">




  <meta name="keywords" content="Docker & Kubernetes & GPU, Kubernetes, Gai's Blog">





  <meta name="google-site-verification" content="SrSETrQ8JjhGYLB-qHgsT23NdViq-VEpvghPoNFdn2g">






  <link rel="alternate" href="/atom.xml" title="Gai's Blog">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.9.0">



<link rel="canonical" href="https://bluesmilery.github.io/blogs/243abda1/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.9.0">



  
  <script id="baidu_analytics">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?a3f2fd48827f9ed28f8d9432317653de";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-121307266-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-121307266-1');
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "BmUgD1geFKBFQpURVdGNzgl1-gzGzoHsz",
      appKey: "mOzxpdEEenjouuAKMFPazvnd"
    });
  </script>




<script>
  window.config = {"title":"Gai's Blog","subtitle":"A Zone for Knowledge","description":null,"author":"Gai","language":null,"timezone":"Europe/Lisbon","url":"https://bluesmilery.github.io","root":"/","permalink":"blogs/:abbrlink/","permalink_defaults":null,"source_dir":"source","public_dir":"public","tag_dir":"tags","archive_dir":"archives","category_dir":"categories","code_dir":"downloads/code","i18n_dir":":lang","skip_render":null,"new_post_name":":year-:month-:day-:title.md","default_layout":"post","titlecase":false,"external_link":true,"filename_case":0,"render_drafts":false,"post_asset_folder":false,"relative_link":false,"future":true,"highlight":{"enable":true,"auto_detect":false,"line_number":true,"tab_replace":null,"first_line_number":"always1"},"default_category":"uncategorized","category_map":null,"tag_map":null,"date_format":"YYYY-MM-DD","time_format":"HH:mm:ss","per_page":10,"pagination_dir":"page","theme":"even","deploy":[{"type":"git","repo":"git@github.com:bluesmilery/bluesmilery.github.io.git","branch":"master"},{"type":"baidu_url_submitter"}],"ignore":[],"keywords":null,"index_generator":{"per_page":10,"order_by":"-date","path":""},"sitemap":{"path":"sitemap.xml"},"baidusitemap":{"path":"baidusitemap.xml"},"abbrlink":{"alg":"crc32","rep":"hex"},"baidu_url_submit":{"count":1,"host":"bluesmilery.github.io","token":"cktimjuXHORRMXsM","path":"baidu_urls.txt"},"archive_generator":{"per_page":10,"yearly":true,"monthly":true,"daily":false},"category_generator":{"per_page":10},"feed":{"type":"atom","limit":20,"hub":"","content":true,"content_limit":140,"content_limit_delim":"","path":"atom.xml"},"tag_generator":{"per_page":10},"marked":{"gfm":true,"pedantic":false,"sanitize":false,"tables":true,"breaks":true,"smartLists":true,"smartypants":true,"modifyAnchors":"","autolink":true},"server":{"port":4000,"log":false,"compress":false,"header":true},"since":2017,"favicon":"/favicon.ico","rss":"default","menu":{"Home":"/","Archives":"/archives/","Tags":"/tags","Categories":"/categories"},"color":"Default","toc":true,"fancybox":true,"pjax":true,"copyright":{"enable":true,"license":"<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\">知识共享署名-非商业性使用 4.0 国际许可协议</a>"},"reward":{"enable":false,"qrCode":{"wechat":null,"alipay":null}},"social":{"email":"plgaixd92498@gmail.com","stack-overflow":null,"twitter":null,"facebook":null,"linkedin":null,"google":null,"github":"https://github.com/bluesmilery","weibo":null,"zhihu":null,"douban":null,"pocket":null,"tumblr":null,"instagram":null},"leancloud":{"app_id":"BmUgD1geFKBFQpURVdGNzgl1-gzGzoHsz","app_key":"mOzxpdEEenjouuAKMFPazvnd"},"baidu_analytics":"a3f2fd48827f9ed28f8d9432317653de","baidu_verification":null,"google_analytics":"UA-121307266-1","google_verification":"SrSETrQ8JjhGYLB-qHgsT23NdViq-VEpvghPoNFdn2g","disqus_shortname":null,"changyan":{"appid":null,"appkey":null},"livere_datauid":"MTAyMC8zMzY4MC8xMDIzNQ","version":"2.9.0","word_count":true};
</script>

    <title> 基于Docker的Kubernetes-1.12集群搭建 - Gai's Blog </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Gai's Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Gai's Blog</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          基于Docker的Kubernetes-1.12集群搭建
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-12-16
        </span>
        
          <div class="post-category">
            
              <a href="/categories/技术/">技术</a>
            
          </div>
        
        
        <div class="post-visits" data-url="/blogs/243abda1/" data-title="基于Docker的Kubernetes-1.12集群搭建">
            阅读次数 0
          </div>
        
        
        
        
          <span class="post-count">本文共4k字</span>
          <span class="post-count">阅读约19分钟</span>
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#系列文章"><span class="toc-text">系列文章</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#环境配置"><span class="toc-text">环境配置</span></a></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#1、安装k8s相关组件"><span class="toc-text">1、安装k8s相关组件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#添加k8s的yum源"><span class="toc-text">添加k8s的yum源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#修改SELinux"><span class="toc-text">修改SELinux</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#关闭Swap"><span class="toc-text">关闭Swap</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#安装k8s"><span class="toc-text">安装k8s</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#一点网络设置"><span class="toc-text">一点网络设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#启动kubelet服务"><span class="toc-text">启动kubelet服务</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、搭建k8s集群"><span class="toc-text">2、搭建k8s集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#初始化Master节点"><span class="toc-text">初始化Master节点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#解决谷歌镜像问题"><span class="toc-text">解决谷歌镜像问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#设置Pod网络方案"><span class="toc-text">设置Pod网络方案</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#执行初始化"><span class="toc-text">执行初始化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置kubectl"><span class="toc-text">配置kubectl</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#安装Pod网络"><span class="toc-text">安装Pod网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#添加Node节点"><span class="toc-text">添加Node节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置Node节点"><span class="toc-text">配置Node节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#一些错误"><span class="toc-text">一些错误</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、小结"><span class="toc-text">3、小结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-text">References</span></a>
    </li></div>
  </div>



    <div class="post-content">
      
        <p>上了Docker怎能不上Kubernetes（下文简称为k8s）呢，k8s是一款旨在提供跨主机集群的自动部署、扩展以及运行应用程序容器的平台。至于它具体是什么，有什么好处，可以自行网络搜索（主要是好处太多了罗列不过来）</p>
<p>本文的主要内容为在腾讯云的GPU服务器上如何安装k8s以及搭建单master节点的k8s集群</p>
<a id="more"></a>
<h3 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h3><p>本文为【Docker &amp; Kubernetes &amp; GPU】系列文章中的一篇。其他文章为：</p>
<ul>
<li><a href="https://bluesmilery.github.io/blogs/252e6902/">Docker安装指南以及使用GPU</a></li>
<li><a href="https://bluesmilery.github.io/blogs/b6607682/">使用Harbor搭建Docker私有仓库</a></li>
</ul>
<h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>本文实践的服务器环境为：</p>
<ul>
<li>CentOS Linux release 7.5.1804 (Core)</li>
<li>内核版本：3.10.0-862.14.4.el7.x86_64</li>
<li>Docker-CE版本：18.06.1-ce</li>
<li>所安装的k8s版本为：1.12.2</li>
</ul>
<h2 id="1、安装k8s相关组件"><a href="#1、安装k8s相关组件" class="headerlink" title="1、安装k8s相关组件"></a>1、安装k8s相关组件</h2><p>以下内容根据官方安装指南进行简化整理，完整版请移步：<a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></p>
<p>因为k8s是谷歌开源的，所以下文涉及的各种下载均需要连接谷歌服务器，而这对于我们来说是不可行的。解决办法有两种：其一是服务器上挂代理；另外就是下载地址替换</p>
<p>注意：需要在所有节点上安装k8s（kubelet、kubeadm、kubectl）以及Docker</p>
<h3 id="添加k8s的yum源"><a href="#添加k8s的yum源" class="headerlink" title="添加k8s的yum源"></a>添加k8s的yum源</h3><p>创建并编辑<code>/etc/yum.repos.d/kubernetes.repo</code>文件，输入以下内容（已将地址替换为阿里的镜像【<a href="https://opsx.alibaba.com/mirror" target="_blank" rel="noopener">阿里镜像站</a>】）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">exclude=kube*</span><br></pre></td></tr></table></figure>
<h3 id="修改SELinux"><a href="#修改SELinux" class="headerlink" title="修改SELinux"></a>修改SELinux</h3><p>因为k8s的pod网络需要访问宿主机文件系统，所以需要将SELinux设置为permissive模式</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set SELinux in permissive mode (effectively disabling it)</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX=permissive/'</span> /etc/selinux/config</span><br></pre></td></tr></table></figure>
<h3 id="关闭Swap"><a href="#关闭Swap" class="headerlink" title="关闭Swap"></a>关闭Swap</h3><p>Kubernetes 1.8开始要求关闭系统的Swap（基于性能的考虑），如果不关闭，默认配置下kubelet将无法启动</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a </span><br><span class="line">sed -i <span class="string">'s/.*swap.*/#&amp;/'</span> /etc/fstab</span><br></pre></td></tr></table></figure>
<h3 id="安装k8s"><a href="#安装k8s" class="headerlink" title="安装k8s"></a>安装k8s</h3><p>为了避免安装过程中繁琐的确认，添加-y参数，一键安装</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br></pre></td></tr></table></figure>
<h3 id="一点网络设置"><a href="#一点网络设置" class="headerlink" title="一点网络设置"></a>一点网络设置</h3><p>因为有些RHEL/CentOS 7的用户报告说iptables被绕过导致流量路由出错，所以需要设置以下内容</p>
<p>创建并编辑<code>/etc/sysctl.d/k8s.conf</code>文件，输入以下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br></pre></td></tr></table></figure>
<p>然后使用<code>sysctl --system</code>查看是否添加成功</p>
<h3 id="启动kubelet服务"><a href="#启动kubelet服务" class="headerlink" title="启动kubelet服务"></a>启动kubelet服务</h3><ol>
<li><p>创建配置链接：<code>systemctl enable kubelet</code></p>
<p>完成后会提示<code>Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.</code></p>
</li>
<li><p>启动服务：<code>systemctl start kubelet</code></p>
</li>
<li><p><strong>（执行完后续的初始化Master再检查，否则看到的是失败状态）</strong></p>
<p>检查服务启动状态：<code>systemctl status kubelet</code></p>
<p>如果看到Active: active (running)那就代表启动成功了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">● kubelet.service - kubelet: The Kubernetes Node Agent</span><br><span class="line">   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /etc/systemd/system/kubelet.service.d</span><br><span class="line">           └─10-kubeadm.conf</span><br><span class="line">   Active: active (running) since 四 2018-11-08 10:33:25 CST; 5h 30min ago</span><br><span class="line">     Docs: https://kubernetes.io/docs/</span><br><span class="line"> Main PID: 29230 (kubelet)</span><br><span class="line">    Tasks: 30</span><br><span class="line">   Memory: 47.9M</span><br><span class="line">   CGroup: /system.slice/kubelet.service</span><br><span class="line">           └─29230 /usr/bin/kubelet --bootst</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果有提示<code>[WARNING Service-Docker]: docker service is not enabled, please run &#39;systemctl enable docker.service&#39;</code>话，就照着执行<code>systemctl enable docker.service</code></p>
</li>
</ol>
<h2 id="2、搭建k8s集群"><a href="#2、搭建k8s集群" class="headerlink" title="2、搭建k8s集群"></a>2、搭建k8s集群</h2><p>此处搭建的是单Master节点，完整版请移步：<a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></p>
<h3 id="初始化Master节点"><a href="#初始化Master节点" class="headerlink" title="初始化Master节点"></a>初始化Master节点</h3><p>基础命令是<code>kubeadm init</code>，不过先别着急执行</p>
<p>初始化Master的过程中会下载一些镜像，因为k8s很多系统组件也是以容器的方式运行。可以先执行<code>kubeadm config images pull</code>尝试下载一下，如果没有设置代理，那么肯定会出现网络错误，因为无法连接谷歌的服务器</p>
<p>关于谷歌镜像的下载解决办法有多种：</p>
<ul>
<li>使用阿里云自己做一个镜像站，修改k8s配置从阿里云下载</li>
<li>使用GitHub同步结合Docker Hub Auto Build</li>
<li>手动下载镜像然后重新打tag</li>
</ul>
<p>另附<a href="https://console.cloud.google.com/gcr/images/google-containers" target="_blank" rel="noopener">Google所有的镜像</a></p>
<p>这里我们采用的是网上一个现成的解决方案：<a href="https://anjia0532.github.io/2017/11/15/gcr-io-image-mirror/" target="_blank" rel="noopener">https://anjia0532.github.io/2017/11/15/gcr-io-image-mirror/</a> ，他将谷歌镜像全部同步到了自己的<a href="https://github.com/anjia0532/gcr.io_mirror" target="_blank" rel="noopener">GitHub</a>仓库中（目前仍在维护）并上传到了Docker Hub中，我们下载下来再重新打tag即可</p>
<h4 id="解决谷歌镜像问题"><a href="#解决谷歌镜像问题" class="headerlink" title="解决谷歌镜像问题"></a>解决谷歌镜像问题</h4><p>那么需要哪些镜像呢，执行<code>kubeadm config images list</code>查看一下。对于k8s 1.12版本需要的是以下镜像及版本（注意，不同k8s版本需要的镜像版本不同）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">k8s.gcr.io/kube-apiserver:v1.12.2</span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.12.2</span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.12.2</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.12.2</span><br><span class="line">k8s.gcr.io/pause:3.1</span><br><span class="line">k8s.gcr.io/etcd:3.2.24</span><br><span class="line">k8s.gcr.io/coredns:1.2.2</span><br></pre></td></tr></table></figure>
<p>将以上内容存到一个文件中，在这里是<code>~/k8s_need_images.dat</code></p>
<p>然后创建并编辑<code>~/retag_images.sh</code>文件，输入以下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">images=(`cat k8s_need_images.dat`)</span><br><span class="line">echo $&#123;images[@]&#125;</span><br><span class="line">for img in $&#123;images[@]&#125;</span><br><span class="line">do</span><br><span class="line">    # 之后还有需要下载的镜像，直接在k8s_need_images.txt文件中添加即可</span><br><span class="line">    # 不需要下载的（比如之前添加过的）前加上#号即可</span><br><span class="line">    # 镜像名既支持k8s.gcr.io开头的，也支持gcr.io/google_containers开头的</span><br><span class="line">    if [[ &quot;$&#123;img:0:1&#125;&quot;x != &quot;#&quot;x ]]; then</span><br><span class="line">        img_name=`echo $img | awk -F &apos;/&apos; &apos;&#123;print $NF&#125;&apos;`</span><br><span class="line">        download_img=&quot;anjia0532/google-containers.$&#123;img_name&#125;&quot;</span><br><span class="line">        echo deal with $img_name</span><br><span class="line">        docker pull $download_img</span><br><span class="line">        docker tag $download_img $img</span><br><span class="line">        docker rmi $download_img</span><br><span class="line">    fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>执行<code>sh ~/retag_images.sh</code> ，稍等一会。完成后使用<code>docker images</code>查看下，所需要的k8s镜像都已存在</p>
<h4 id="设置Pod网络方案"><a href="#设置Pod网络方案" class="headerlink" title="设置Pod网络方案"></a>设置Pod网络方案</h4><p>初始化Master的时候，还需要做的一件事情是要选择一种Pod网络方案。k8s提供了许多种网络方案，这里我们选择使用Flannel，那么在初始化的时候还需要加上参数<code>--pod-network-cidr=10.244.0.0/16</code></p>
<h4 id="执行初始化"><a href="#执行初始化" class="headerlink" title="执行初始化"></a>执行初始化</h4><p>执行<code>kubeadm init --pod-network-cidr=10.244.0.0/16</code></p>
<p>然后可以看到以下日志内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">[init] using Kubernetes version: v1.12.2</span><br><span class="line">[preflight] running pre-flight checks</span><br><span class="line">[preflight/images] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight/images] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[preflight] Activating the kubelet service</span><br><span class="line">[certificates] Generated ca certificate and key.</span><br><span class="line">[certificates] Generated apiserver certificate and key.</span><br><span class="line">[certificates] apiserver serving cert is signed for DNS names [your.hostname1.com kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 hostname1-ip]</span><br><span class="line">[certificates] Generated apiserver-kubelet-client certificate and key.</span><br><span class="line">[certificates] Generated front-proxy-ca certificate and key.</span><br><span class="line">[certificates] Generated front-proxy-client certificate and key.</span><br><span class="line">[certificates] Generated etcd/ca certificate and key.</span><br><span class="line">[certificates] Generated etcd/healthcheck-client certificate and key.</span><br><span class="line">[certificates] Generated apiserver-etcd-client certificate and key.</span><br><span class="line">[certificates] Generated etcd/server certificate and key.</span><br><span class="line">[certificates] etcd/server serving cert is signed for DNS names [your.hostname1.com localhost] and IPs [127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/peer certificate and key.</span><br><span class="line">[certificates] etcd/peer serving cert is signed for DNS names [your.hostname1.com localhost] and IPs [hostname1-ip 127.0.0.1 ::1]</span><br><span class="line">[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certificates] Generated sa key and public key.</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;</span><br><span class="line">[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;</span><br><span class="line">[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[init] this might take a minute or longer if the control plane images have to be pulled</span><br><span class="line">[apiclient] All control plane components are healthy after 20.502026 seconds</span><br><span class="line">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.12&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[markmaster] Marking the node your.hostname1.com as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[markmaster] Marking the node your.hostname1.com as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;your.hostname1.com&quot; as an annotation</span><br><span class="line">[bootstraptoken] using token: gnafk2.7b1lq8543rhbcsbz</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join hostname1-ip:6443 --token gnafk2.7b1lq8543rhbcsbz --discovery-token-ca-cert-hash sha256:d2296123b1364d26678b1f92210d54fa4bb36455ffbcd665e9f04e05288b7b34</span><br></pre></td></tr></table></figure>
<p>看到successfully以及检查kubelet服务状态为active (running)的话就代表Master节点初始化成功了</p>
<p>不过根据日志内容，提示我们还需要干三件事</p>
<h3 id="配置kubectl"><a href="#配置kubectl" class="headerlink" title="配置kubectl"></a>配置kubectl</h3><p>为了让非root用户（比如work用户）也能使用kubectl来管理k8s集群，需要执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure>
<p>对于root用户，既可以使用上述方法（推荐），也可以只执行<code>export KUBECONFIG=/etc/kubernetes/admin.conf</code>，不过对于每开一个新shell都需要export太麻烦了，还是推荐上述方法</p>
<p>对于需要使用kubectl的用户，还可以执行以下命令以便启用kubectl命令补全功能：<code>echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</code></p>
<h3 id="安装Pod网络"><a href="#安装Pod网络" class="headerlink" title="安装Pod网络"></a>安装Pod网络</h3><p>为了能让集群的Pod之间进行通讯，需要安装Pod网络，执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>
<h3 id="添加Node节点"><a href="#添加Node节点" class="headerlink" title="添加Node节点"></a>添加Node节点</h3><p>在要作为Node节点的服务器上，执行初始化Master成功后日志中提示的内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join hostname1-ip:6443 --token gnafk2.7b1lq8543rhbcsbz --discovery-token-ca-cert-hash sha256:d2296123b1364d26678b1f92210d54fa4bb36455ffbcd665e9f04e05288b7b34</span><br></pre></td></tr></table></figure>
<p>注意，Master节点初始化成功后生成的token有效期为24小时，如果token失效的了话可以重新生成，具体可见<a href="https://bluesmilery.github.io/blogs/243abda1/#%E4%B8%80%E4%BA%9B%E9%94%99%E8%AF%AF">一些错误</a>部分</p>
<p>如果执行成功的话会看到以下日志内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[preflight] running pre-flight checks</span><br><span class="line">[discovery] Trying to connect to API Server &quot;hostname1-ip:6443&quot;</span><br><span class="line">[discovery] Created cluster-info discovery client, requesting info from &quot;https://hostname1-ip:6443&quot;</span><br><span class="line">[discovery] Requesting info from &quot;https://hostname1-ip:6443&quot; again to validate TLS against the pinned public key</span><br><span class="line">[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &quot;hostname1-ip:6443&quot;</span><br><span class="line">[discovery] Successfully established connection with API Server &quot;hostname1-ip:6443&quot;</span><br><span class="line">[kubelet] Downloading configuration for the kubelet from the &quot;kubelet-config-1.12&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[preflight] Activating the kubelet service</span><br><span class="line">[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;your.hostname3.com&quot; as an annotation</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; on the master to see this node join the cluster.</span><br></pre></td></tr></table></figure>
<p>看到joined可以确认Node节点添加成功</p>
<h3 id="配置Node节点"><a href="#配置Node节点" class="headerlink" title="配置Node节点"></a>配置Node节点</h3><p>在Master节点上执行<code>kubectl get nodes</code>命令，可以看到节点状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                 STATUS     ROLES    AGE    VERSION</span><br><span class="line">your.hostname3.com   NotReady   &lt;none&gt;   19m    v1.12.2</span><br><span class="line">your.hostname2.com   NotReady   &lt;none&gt;   6s     v1.12.2</span><br><span class="line">your.hostname1.com   Ready      master   110m   v1.12.2</span><br></pre></td></tr></table></figure>
<p>这里添加了两个Node节点，出现在这里也可以确认Node节点添加成功。不过可以看到两台Node节点的STATUS为NotReady，这是因为Node节点也需要启动一些组件，这些组件运行在Pod中</p>
<p>使用<code>kubectl get pod --all-namespaces</code>查看集群上运行的所有Pod</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">NAMESPACE     NAME                                                  READY   STATUS              RESTARTS   AGE</span><br><span class="line">kube-system   coredns-576cbf47c7-dv4wr                              1/1     Running             0          117m</span><br><span class="line">kube-system   coredns-576cbf47c7-mq9kp                              1/1     Running             0          117m</span><br><span class="line">kube-system   etcd-your.hostname1.com                               1/1     Running             0          116m</span><br><span class="line">kube-system   kube-apiserver-your.hostname1.com                     1/1     Running             0          116m</span><br><span class="line">kube-system   kube-controller-manager-your.hostname1.com            1/1     Running             0          116m</span><br><span class="line">kube-system   kube-flannel-ds-amd64-fpw9b                           0/1     Init:0/1            0          26m</span><br><span class="line">kube-system   kube-flannel-ds-amd64-lp8kn                           0/1     Init:0/1            0          7m47s</span><br><span class="line">kube-system   kube-flannel-ds-amd64-qzrlb                           1/1     Running             0          34m</span><br><span class="line">kube-system   kube-proxy-96kzl                                      0/1     ContainerCreating   0          26m</span><br><span class="line">kube-system   kube-proxy-vb28n                                      1/1     Running             0          117m</span><br><span class="line">kube-system   kube-proxy-w62pn                                      0/1     ContainerCreating   0          7m47s</span><br><span class="line">kube-system   kube-scheduler-your.hostname1.com                     1/1     Running             0          116m</span><br></pre></td></tr></table></figure>
<p>会看到有一些Pod并没有正常运行（在这里是两个kube-proxy和两个kube-flannel），使用<code>kubectl describe pod kube-proxy-96kzl --namespace=kube-system</code>查看其中一个。返回内容最下面部分的Events记录了一些信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Events:</span><br><span class="line">  Type     Reason                  Age                  From                                  Message</span><br><span class="line">  ----     ------                  ----                 ----                                  -------</span><br><span class="line">  Warning  DNSConfigForming        10m (x151 over 80m)  kubelet, your.hostname3.com  Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 127.0.0.1 xx.xx.xx.xx xx.xx.xx.xx</span><br><span class="line">  Warning  FailedCreatePodSandBox  46s (x172 over 80m)  kubelet, your.hostname3.com  Failed create pod sandbox: rpc error: code = Unknown desc = failed pulling image &quot;k8s.gcr.io/pause:3.1&quot;: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</span><br></pre></td></tr></table></figure>
<p>可以看到是因为下载<code>k8s.gcr.io/pause:3.1</code>这个docker镜像失败了，原因自然是因为无法连接谷歌服务器。经过测试，在Node节点上总共需要下载以下两个镜像外加一个正常网络可以下载的<code>quay.io/coreos/flannel:v0.10.0-amd64</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k8s.gcr.io/pause:3.1</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.12.2</span><br></pre></td></tr></table></figure>
<p>所以可以在Node节点上使用文章前部所使用的<a href="https://bluesmilery.github.io/blogs/243abda1/#%E8%A7%A3%E5%86%B3%E8%B0%B7%E6%AD%8C%E9%95%9C%E5%83%8F%E9%97%AE%E9%A2%98">解决谷歌镜像问题</a>方法来下载这两个镜像</p>
<p>下载完成后，稍等一会再使用<code>kubectl get pod --all-namespaces</code>查看，可以发现所有的Pod都是Running状态了，使用<code>kubectl get nodes</code>查看也可以发现所有Node节点为Ready状态</p>
<p>至此，k8s集群搭建完成</p>
<h3 id="一些错误"><a href="#一些错误" class="headerlink" title="一些错误"></a>一些错误</h3><ul>
<li>[WARNING Service-Docker]: docker service is not enabled, please run ‘systemctl enable docker.service’</li>
</ul>
<p>没有关联docker服务的配置文件。照着执行<code>systemctl enable docker.service</code>即可</p>
<ul>
<li><p>[WARNING RequiredIPVSKernelModulesAvailable]: the IPVS proxier will not be used, because the following required kernel modules are not loaded: [ip_vs_sh ip_vs ip_vs_rr ip_vs_wrr] or no builtin kernel ipvs support: map[ip_vs:{} ip_vs_rr:{} ip_vs_wrr:{} ip_vs_sh:{} nf_conntrack_ipv4:{}]<br>you can solve this problem with following methods:</p>
<p>​    1.Run ‘modprobe – ‘ to load missing kernel modules;</p>
<p>​    2.Provide the missing builtin kernel ipvs support</p>
</li>
</ul>
<p>有一些内核模块没有加载，执行<code>modprobe -va ip_vs_sh ip_vs ip_vs_rr ip_vs_wrr</code>即可</p>
<ul>
<li>[discovery] Failed to connect to API Server “hostname1-ip:6443”: token id “ztsrrn” is invalid for this cluster or it has expired. Use “kubeadm token create” on the master node to creating a new valid token</li>
</ul>
<p>在添加Node节点时报的错误，是因为token过期。在Master节点上执行<code>kubeadm token create</code>重新生成token。并且需要重新获取CA的hash值，否则会出现cluster CA found in cluster-info configmap is invalid的错误。再执行<code>openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39;</code>，获取到新token以及新CA的hash值后，重新添加Node节点即可</p>
<ul>
<li>Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of “crypto/rsa: verification error” while trying to verify candidate authority certificate “kubernetes”)</li>
</ul>
<p>没有配置kubelet，导致TLS证书不匹配</p>
<ul>
<li>Node节点手动下载了相关镜像，但是Pod状态仍不发生改变</li>
</ul>
<p>这个是时候可能是相关Pod在某个地方卡住了，可以使用<code>kubectl delete pod xxx --namespace=kube-system</code>将卡住的Pod删除，集群会自动重新生成相关Pod，然后就能使用手动下载的镜像了</p>
<h2 id="3、小结"><a href="#3、小结" class="headerlink" title="3、小结"></a>3、小结</h2><p>至此便完成了单master节点的搭建，如果在生产环境使用，还是推荐搭建HA多master</p>
<p>本文使用了官方提供的kubeadm工具进行配置，非常简单易用。不过网上也有好多使用二进制文件进行配置的，虽然烦琐一些但是对k8s的原理会有更深入的理解。读者可以根据需要选择更适合自己的方式</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>在这里有个微服务部署在k8s集群上的demo，可以试用感受一下</p>
<ul>
<li>k8s集群使用微服务Demo：<a href="https://microservices-demo.github.io/deployment/kubernetes-start.html" target="_blank" rel="noopener">https://microservices-demo.github.io/deployment/kubernetes-start.html</a></li>
</ul>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="https://bluesmilery.github.io">Gai</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="https://bluesmilery.github.io/blogs/243abda1/">https://bluesmilery.github.io/blogs/243abda1/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/Docker-Kubernetes-GPU/">Docker & Kubernetes & GPU</a>
            
              <a href="/tags/Kubernetes/">Kubernetes</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
    
      <a class="next" href="/blogs/b6607682/">
        <span class="next-text nav-default">使用Harbor搭建Docker私有仓库</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMzY4MC8xMDIzNQ">
        <noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
      </div>  
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


  <div class="social-links">
    
      
        
          <a href="mailto:plgaixd92498@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/bluesmilery" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
    
    
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  
  <br>
  <span id="busuanzi_container_site_uv">
    被<span id="busuanzi_value_site_uv"></span>个小伙伴
  </span>
  <span id="busuanzi_container_site_pv">
    查看了<span id="busuanzi_value_site_pv"></span>次~
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2017 - 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Gai</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  
   <script type="text/javascript">
	(function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
  </script>




    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.9.0"></script>

  </body>
</html>
